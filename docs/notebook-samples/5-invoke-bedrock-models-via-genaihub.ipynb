{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for invoking Anthropic and Titan Family of models via SAP GenAI Hub on SAP AI core\n",
    "\n",
    "## Part 1: Use AI Core REST APIs\n",
    "\n",
    "Use this notebook to invoke the AI Core REST APIs to send your payloads into LLMs hosted on SAP GenAI hub. The documentation for the APIs are provided [here](https://api.sap.com/api/AI_CORE_API/resource/Deployment).\n",
    "\n",
    "\n",
    "## Part 2: Use SAP Generative AI Hub SDK\n",
    "Sample code to invoke Anthropic and Titan Family of models using the ChatBedrock interface in the SAP Generative AI Hub SDK. Documentation [here](https://pypi.org/project/generative-ai-hub-sdk/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1:\n",
    "### Step 1: Load your AI Core credentials\n",
    "\n",
    "After following the steps in the previous notebook to setup the AI Core instance, Configurations and Deployments for Bedrock models, you can invoke the models via the following approach. \n",
    "\n",
    "First, you should have your AI core creadentials in your ~/.aicore/config.json. If you do not, get it by creating a service key from [here](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-service-key). We will read and consume the data from this location into temporary environment files for this notebook.\n",
    "\n",
    "A sample config.json is below:\n",
    "\n",
    "```sh\n",
    "$ cat ~/.aicore/config.json  \n",
    "{\n",
    "  \"AICORE_AUTH_URL\": \"<>.authentication.us10.hana.ondemand.com\",\n",
    "  \"AICORE_CLIENT_ID\": \"sb-b...64\",\n",
    "  \"AICORE_CLIENT_SECRET\": \"21...xc=\",\n",
    "  \"AICORE_RESOURCE_GROUP\": \"default\",\n",
    "  \"AICORE_BASE_URL\": \"https://api.ai.prod.<>.ondemand.com\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "\n",
    "def load_config():\n",
    "    with open(os.path.expanduser('~/.aicore/config.json')) as f:\n",
    "        config = json.load(f)\n",
    "    for key, value in config.items():\n",
    "        os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Uncomment the line which has the model you would like to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/models-and-scenarios-in-generative-ai-hub or uncomment from below\n",
    "\n",
    "# Multimodal models:\n",
    "os.environ[\"TARGET_AI_CORE_MODEL\"] = \"anthropic--claude-3.5-sonnet\"\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"anthropic--claude-3-opus\"\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"anthropic--claude-3-sonnet\"\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"anthropic--claude-3-haiku\"\n",
    "\n",
    "#Text based models:\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"amazon--titan-text-lite\"\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"amazon--titan-text-express\"\n",
    "\n",
    "# Embedding models:\n",
    "# os.environ[\"TARGET_AI_CORE_MODEL\"] = \"amazon--titan-embed-text\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Step: If you know the deployment ID from AI Launchpad already, you can uncomment below. This way you don't need to speicify the model name in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL:\n",
    "# Uncomment the below line after pasting your deployment ID if you already know it\n",
    "# os.environ[\"DEPLOYMENT_ID\"] = \"<>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Utility functions\n",
    "Creating a utility function to send API calls to AI Core instance repeatedly. You will need to install requests library in the terminal \n",
    "```sh\n",
    "pip install requests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "from util.logging import initLogger\n",
    "\n",
    "TIME_RETRY_API_CALL = 20\n",
    "TIMEOUT_API_CALL = 3600\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "initLogger()\n",
    "\n",
    "\n",
    "# Function to call a rest API\n",
    "def call_api(\n",
    "    type: str, url: str, headers: dict, data: dict = None, message: str = None\n",
    "):\n",
    "    timeNeeded = 0\n",
    "    while timeNeeded < TIMEOUT_API_CALL:\n",
    "        try:\n",
    "            r = None\n",
    "            # Send the request to retrieve the access token\n",
    "            if type == \"POST\":\n",
    "                r = requests.post(url=url, headers=headers, data=data)\n",
    "            elif type == \"GET\":\n",
    "                r = requests.get(url=url, headers=headers)\n",
    "            # if the response is OK, return the JSON response\n",
    "            if r.ok is True:\n",
    "                log.success(f\"{message}\")\n",
    "                return r.json()\n",
    "            else:\n",
    "                log.info(\n",
    "                    f\"response ({message}): {r.status_code} ({r.reason}): {r.text}\"\n",
    "                )\n",
    "                log.warning(\n",
    "                    f\"Could not {message}! Re-trying in {TIME_RETRY_API_CALL} seconds...\"\n",
    "                )\n",
    "                time.sleep(TIME_RETRY_API_CALL)\n",
    "                timeNeeded += TIME_RETRY_API_CALL\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            log.warning(str(e))\n",
    "            log.error(f\"Could not {message}! Exiting...\")\n",
    "            sys.exit(1)\n",
    "    log.error(f\"Could not {message} after {TIMEOUT_API_CALL} seconds! Exiting...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a template to hold the deploymentURL and other imporatant parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from json import JSONEncoder\n",
    "\n",
    "\n",
    "class AiCoreMetadataJsonEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AiCoreMetadataDefinition:\n",
    "    authUrl: str\n",
    "    clientId: str\n",
    "    clientSecret: str\n",
    "    apiBase: str\n",
    "    resourceGroup: str\n",
    "    targetAiCoreModel: str\n",
    "    apiAccessToken: str\n",
    "    deploymentUrl : str\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return getattr(self, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataClass that will initiate with the environment variables that have the AI Core credentials as well as the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AiCoreMetadata(AiCoreMetadataDefinition):\n",
    "    def __init__(self):\n",
    "\n",
    "        load_config()\n",
    "\n",
    "        self.authUrl = os.environ.get(\"AICORE_AUTH_URL\")\n",
    "        self.clientId = os.environ.get(\"AICORE_CLIENT_ID\")\n",
    "        self.clientSecret = os.environ.get(\"AICORE_CLIENT_SECRET\")\n",
    "        self.resourceGroup = os.environ.get(\"AICORE_RESOURCE_GROUP\")\n",
    "        self.apiBase = os.environ.get(\"AICORE_BASE_URL\")\n",
    "        self.targetAiCoreModel = os.environ.get(\"TARGET_AI_CORE_MODEL\")\n",
    "        self.apiAccessToken = get_api_access_token(self)\n",
    "        self.deploymentUrl = get_deployment_details_for_model(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a utility function that will get the API Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_access_token(aiCoreMetadata: AiCoreMetadataDefinition) -> str:\n",
    "    clientId = aiCoreMetadata.clientId\n",
    "    clientSecret = aiCoreMetadata.clientSecret\n",
    "    authUrl = aiCoreMetadata.authUrl\n",
    "\n",
    "    # Create the authorization string\n",
    "    authorizationString = f\"{clientId}:{clientSecret}\"\n",
    "    # Encode the authorization string\n",
    "    byte_data = authorizationString.encode(\"utf-8\")\n",
    "    # Base64 encode the byte data\n",
    "    clientSecretBase64 = base64.b64encode(byte_data).decode(\"utf-8\")\n",
    "\n",
    "    # Create the URL to retrieve the access token\n",
    "    aiCoreLocation = f\"{authUrl}/oauth/token?grant_type=client_credentials\"\n",
    "    # Create the headers for the request\n",
    "    headers = {\"Authorization\": f\"Basic {clientSecretBase64}\"}\n",
    "\n",
    "    response = call_api(\n",
    "        \"POST\",\n",
    "        aiCoreLocation,\n",
    "        headers,\n",
    "        None,\n",
    "        \"retrieve access token from AI Core system\",\n",
    "    )\n",
    "    # json_response = json.dumps(response, indent=2)\n",
    "\n",
    "    return response[\"access_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the API Access token, lets get the deployment URL that corresponds to the Model you want to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the deployment URL from the AI Core system metadata\n",
    "def get_deployment_details_for_model(aiCoreMetadata: AiCoreMetadataDefinition):\n",
    "    apiBase = aiCoreMetadata.apiBase\n",
    "    token = aiCoreMetadata.apiAccessToken\n",
    "    resourceGroup = aiCoreMetadata.resourceGroup\n",
    "\n",
    "    # Create the URL to get the deployment \n",
    "    aiCoreLocation = f\"{apiBase}/v2/lm/deployments\"\n",
    "    # Create the headers for the request\n",
    "    headers = {}\n",
    "    headers[\"AI-Resource-Group\"] = resourceGroup\n",
    "    headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    allDeploymentDetails = None\n",
    "\n",
    "    timeNeeded = 0\n",
    "    message = f\"retrieve deployment details for model id {aiCoreMetadata.targetAiCoreModel}\"\n",
    "    while timeNeeded < TIMEOUT_API_CALL:\n",
    "        # Send the request to get the list of deployments\n",
    "        response = call_api(\"GET\", aiCoreLocation, headers, None, message)\n",
    "        json_response = json.dumps(response, indent=2)\n",
    "        log.check(\n",
    "                f\"API response from retrieveing deployment details for model id {aiCoreMetadata.targetAiCoreModel}:\\n{json_response}\"\n",
    "        )\n",
    "\n",
    "        allDeploymentDetails = response\n",
    "    \n",
    "        for resource in allDeploymentDetails[\"resources\"]:\n",
    "            model_name = resource[\"details\"][\"resources\"][\"backend_details\"][\"model\"][\"name\"]\n",
    "            if model_name == aiCoreMetadata.targetAiCoreModel:\n",
    "                return resource[\"deploymentUrl\"]\n",
    "        \n",
    "        log.warning(\n",
    "                f\"Could not {message} Re-trying in {TIME_RETRY_API_CALL} seconds...\"\n",
    "            )\n",
    "\n",
    "        time.sleep(TIME_RETRY_API_CALL)\n",
    "        timeNeeded += TIME_RETRY_API_CALL\n",
    "\n",
    "    log.error(\n",
    "        f\"Could not retrieve deployment details for id '{aiCoreMetadata.targetAiCoreModel}'! Exiting...\"\n",
    "    )\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another utility function to get deployment details in case deployment ID is provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the deployment URL from the AI Core system metadata\n",
    "def get_deployment_details(aiCoreMetadata: AiCoreMetadataDefinition, deploymenId: str):\n",
    "    apiBase = aiCoreMetadata.apiBase\n",
    "    token = aiCoreMetadata.apiAccessToken\n",
    "    resourceGroup = aiCoreMetadata.resourceGroup\n",
    "\n",
    "    # Create the URL to create the configuration\n",
    "    aiCoreLocation = f\"{apiBase}/v2/lm/deployments/{deploymenId}\"\n",
    "    # Create the headers for the request\n",
    "    headers = {}\n",
    "    headers[\"AI-Resource-Group\"] = resourceGroup\n",
    "    headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    deploymentDetails = None\n",
    "\n",
    "    timeNeeded = 0\n",
    "    message = f\"retrieve deployment details for deployment id {deploymenId}\"\n",
    "    while timeNeeded < TIMEOUT_API_CALL:\n",
    "        # Send the request to create the deployment\n",
    "        response = call_api(\"GET\", aiCoreLocation, headers, None, message)\n",
    "        # json_response = json.dumps(response, indent=2)\n",
    "\n",
    "        deploymentDetails = response\n",
    "        deploymentUrl = deploymentDetails[\"deploymentUrl\"]\n",
    "        if deploymentUrl != \"\":\n",
    "            log.success(f\"AI Core deployment id '{deploymenId}' is now accessible!\")\n",
    "            return deploymentDetails\n",
    "        else:\n",
    "            log.warning(\n",
    "                f\"Could not {message} (deployment not finished)! Re-trying in {TIME_RETRY_API_CALL} seconds...\"\n",
    "            )\n",
    "\n",
    "            time.sleep(TIME_RETRY_API_CALL)\n",
    "            timeNeeded += TIME_RETRY_API_CALL\n",
    "\n",
    "    log.error(\n",
    "        f\"Could not retrieve deployment details for id '{deploymenId}'! Exiting...\"\n",
    "    )\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate our class. This step will populate the internal environment variables, execute the access token get utility function and also get the deployment URL for the model specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the metadata for the AI Core system\n",
    "ai_core_metadata = AiCoreMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Step - execute only if you directly want to specify the deployment URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you have provided deployment ID directly instead of model id \n",
    "if ai_core_metadata.deploymentUrl == None:\n",
    "    deploymentDetails = get_deployment_details(ai_core_metadata, os.environ[\"DEPLOYMENT_ID\"])\n",
    "    ai_core_metadata.deploymentUrl = deploymentDetails[\"deploymentUrl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the utility function to send your input prompt to GenAI Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the available AI models from the AI Core system\n",
    "def invoke(aiCoreMetadata: AiCoreMetadataDefinition, \n",
    "           messages,\n",
    "           max_tokens = 1000) -> str:\n",
    "\n",
    "    token = aiCoreMetadata.apiAccessToken\n",
    "    deploymentUrl = aiCoreMetadata.deploymentUrl\n",
    "    \n",
    "    # Create the URL to retrieve the available AI models\n",
    "    aiCoreLocation = f\"{deploymentUrl}/invoke\"\n",
    "    # Create the headers for the request\n",
    "    headers = {\n",
    "        \"AI-Resource-Group\": aiCoreMetadata.resourceGroup,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "    }\n",
    "\n",
    "    data = {}\n",
    "    data[\"anthropic_version\"] = \"bedrock-2023-05-31\"\n",
    "    data[\"max_tokens\"] = max_tokens\n",
    "    data[\"messages\"] = messages\n",
    "    \n",
    "    response = call_api(\n",
    "        \"POST\",\n",
    "        aiCoreLocation,\n",
    "        headers,\n",
    "        json.dumps(data),\n",
    "        \"sending invoke\",\n",
    "    )\n",
    "    json_response = json.dumps(response, indent=2)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a payload in the messages format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello, What is the capital of United States?\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally get a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;241m[2024-10-01 14:41:48] \u001b[38;5;40mSUCCESS: sending invoke\u001b[0;0m\n",
      "\u001b[38;5;241m[2024-10-01 14:41:48] \u001b[38;5;40mSUCCESS: sending invoke\u001b[0;0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': [{'text': \"The capital of the United States is Washington, D.C.\\n\\nWashington, D.C. (District of Columbia) is located on the east coast of the country, between the states of Maryland and Virginia. It was founded in 1790 and named after the first U.S. President, George Washington.\\n\\nAs the capital, Washington, D.C. is the seat of the federal government and home to important national landmarks and institutions, including:\\n\\n1. The White House (residence and office of the President)\\n2. The U.S. Capitol Building (where Congress meets)\\n3. The Supreme Court\\n4. Various national monuments and museums\\n\\nIt's important to note that Washington, D.C. is not a state, but a federal district with a special administrative status.\",\n",
       "   'type': 'text'}],\n",
       " 'id': 'msg_bdrk_01F1XMh7vjuCNTUm5xE4dqxy',\n",
       " 'model': 'claude-3-5-sonnet-20240620',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'input_tokens': 17, 'output_tokens': 168}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke(aiCoreMetadata= ai_core_metadata, \n",
    "       messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Use SAP Generative AI Hub SDK\n",
    "Sample code to invoke Anthropic and Titan Family of models using the ChatBedrock interface in the SAP Generative AI Hub SDK. Documentation [here](https://pypi.org/project/generative-ai-hub-sdk/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install generative-ai-hub-sdk langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain.amazon import ChatBedrock\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = get_proxy_client(\"gen-ai-hub\")\n",
    "llm_via_bedrock_on_GenAIHub = ChatBedrock(\n",
    "        model_name=\"anthropic--claude-3-sonnet\",\n",
    "        proxy_client=proxy_client,\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "  File \"/var/folders/h8/phpnm21538x1ycd922fcjzsw0000gr/T/ipykernel_49705/3424749442.py\", line 6, in <module>\n",
      "    response_body = llm_via_bedrock_on_GenAIHub.invoke(messages)\n",
      "NameError: name 'llm_via_bedrock_on_GenAIHub' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/Users/abhshia/Documents/code/sapaicore_testing/.venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        ( \"system\", \"You are a helpful assistant\" ),\n",
    "        ( \"user\", \"Hello, Claude\" )\n",
    "        ]\n",
    "\n",
    "response_body = llm_via_bedrock_on_GenAIHub.invoke(messages)\n",
    "print(response_body.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
